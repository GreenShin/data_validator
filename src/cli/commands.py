"""
Command-line interface for CSV validation.

ì´ ëª¨ë“ˆì€ ì‚¬ìš©ì ì¹œí™”ì ì¸ ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
from pathlib import Path
from typing import Optional

import click

from ..core.validator import DataValidator
from ..utils.logger import Logger


@click.group()
@click.version_option(version="0.2.0", prog_name="Data Validator")
def cli():
    """
    ë°ì´í„° íŒŒì¼ êµ¬ë¬¸ì •í™•ì„± ê²€ì¦ í”„ë¡œê·¸ë¨

    CSV, JSON, JSONL íŒŒì¼ì˜ êµ¬ì¡°ì •í™•ì„±ê³¼ í˜•ì‹ì •í™•ì„±ì„ ê²€ì¦í•˜ê³  ìƒì„¸í•œ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    pass


@cli.command()
@click.option(
    "--config",
    "-c",
    required=True,
    type=click.Path(exists=True, readable=True),
    help="YAML ì„¤ì • íŒŒì¼ ê²½ë¡œ",
)
@click.option(
    "--input",
    "-i",
    required=True,
    type=click.Path(exists=True),
    help="ê²€ì¦í•  íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œ (CSV, JSON, JSONL ì§€ì›)",
)
@click.option(
    "--output",
    "-o",
    type=click.Path(),
    help="ê²°ê³¼ íŒŒì¼ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: ì…ë ¥ ê²½ë¡œì™€ ë™ì¼)",
)
@click.option("--verbose", "-v", is_flag=True, help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
@click.option("--log-file", type=click.Path(), help="ë¡œê·¸ íŒŒì¼ ê²½ë¡œ")
@click.option(
    "--format",
    type=click.Choice(["markdown", "html", "json", "all"], case_sensitive=False),
    default="all",
    help="ê²°ê³¼ ë¦¬í¬íŠ¸ í˜•ì‹ (ê¸°ë³¸ê°’: all)",
)
@click.option(
    "--analyze",
    is_flag=True,
    help="ì»¬ëŸ¼ ë¶„í¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ì„¤ì • íŒŒì¼ì— distribution_analysis ì„¹ì…˜ì´ í•„ìš”)",
)
def validate(config, input, output, verbose, log_file, format, analyze):
    """
    ë°ì´í„° íŒŒì¼ì˜ êµ¬ë¬¸ì •í™•ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤ (CSV, JSON, JSONL ì§€ì›).

    ì˜ˆì‹œ:
        data-validator validate -c config.yml -i data.csv
        data-validator validate -c config.yml -i data.json
        data-validator validate -c config.yml -i data.jsonl
        data-validator validate -c config.yml -i /path/to/files -o /path/to/results
    """
    try:
        # ì…ë ¥ ê²½ë¡œ í™•ì¸
        input_path = Path(input)
        if not input_path.exists():
            click.echo(f"âŒ ì…ë ¥ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input}", err=True)
            sys.exit(1)

        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        if output is None:
            if input_path.is_file():
                output = input_path.parent
            else:
                output = input_path
        else:
            output = Path(output)
            output.mkdir(parents=True, exist_ok=True)

        # Data Validator ì´ˆê¸°í™”
        validator = DataValidator(config_path=config, verbose=verbose, log_file=log_file)
        
        # ë¶„í¬ ë¶„ì„ ì˜µì…˜ ì²˜ë¦¬
        if analyze:
            if verbose:
                click.echo("ğŸ“Š ë¶„í¬ ë¶„ì„ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            validator.enable_distribution_analysis()

        # ê²€ì¦ ì‹¤í–‰
        if input_path.is_file():
            # ë‹¨ì¼ íŒŒì¼ ê²€ì¦
            supported_extensions = {".csv", ".json", ".jsonl"}
            if input_path.suffix.lower() not in supported_extensions:
                click.echo(f"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {input_path}", err=True)
                click.echo(f"ì§€ì›ë˜ëŠ” í˜•ì‹: {', '.join(supported_extensions)}", err=True)
                sys.exit(1)

            result = validator.validate_file(str(input_path))

            # ê²°ê³¼ ì €ì¥
            _save_single_result(result, output, format, validator)

        elif input_path.is_dir():
            # í´ë” ë‚´ ëª¨ë“  ì§€ì›ë˜ëŠ” íŒŒì¼ ê²€ì¦
            results = validator.validate_folder(str(input_path), str(output))

            if not results:
                click.echo("âš ï¸ ê²€ì¦í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", err=True)
                sys.exit(1)

            # ì „ì²´ ê²°ê³¼ ìš”ì•½
            _print_summary(results)

        else:
            click.echo(f"âŒ ì˜ëª»ëœ ì…ë ¥ ê²½ë¡œì…ë‹ˆë‹¤: {input_path}", err=True)
            sys.exit(1)

        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        validator.close()

        click.echo("âœ… ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        click.echo(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", err=True)
        if verbose:
            import traceback

            click.echo(traceback.format_exc(), err=True)
        sys.exit(1)


@cli.command()
@click.option(
    "--output",
    "-o",
    type=click.Path(),
    default="sample_config.yml",
    help="ìƒì„±í•  ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: sample_config.yml)",
)
@click.option(
    "--type",
    "-t",
    type=click.Choice(["csv", "json", "jsonl"], case_sensitive=False),
    default="csv",
    help="ìƒì„±í•  ìƒ˜í”Œ ì„¤ì • íŒŒì¼ íƒ€ì… (ê¸°ë³¸ê°’: csv)",
)
@click.option("--verbose", "-v", is_flag=True, help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
def init(output, type, verbose):
    """
    ìƒ˜í”Œ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
        data-validator init
        data-validator init -t json -o json_config.yml
        data-validator init -t jsonl -o jsonl_config.yml
    """
    try:
        # ë”ë¯¸ ì„¤ì • íŒŒì¼ë¡œ ConfigManager ì´ˆê¸°í™”
        from ..core.config import ConfigManager

        config_manager = ConfigManager()

        # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±
        if type == "csv":
            config_manager.create_sample_config(output)
        elif type == "json":
            config_manager.create_json_sample_config(output)
        elif type == "jsonl":
            config_manager.create_jsonl_sample_config(output)

        if verbose:
            click.echo(f"âœ… ìƒ˜í”Œ ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output}")
        else:
            click.echo(f"âœ… ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {output}")

        # ì‚¬ìš©ë²• ì•ˆë‚´
        click.echo("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        click.echo(f"1. {output} íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ê²€ì¦ ê·œì¹™ì„ ì„¤ì •í•˜ì„¸ìš”")
        click.echo(
            "2. data-validator validate -c <ì„¤ì •íŒŒì¼> -i <íŒŒì¼> ëª…ë ¹ìœ¼ë¡œ ê²€ì¦ì„ ì‹¤í–‰í•˜ì„¸ìš”"
        )

    except Exception as e:
        click.echo(f"âŒ ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", err=True)
        sys.exit(1)


@cli.command()
@click.option(
    "--config",
    "-c",
    required=True,
    type=click.Path(exists=True, readable=True),
    help="ê²€ì¦í•  YAML ì„¤ì • íŒŒì¼ ê²½ë¡œ",
)
@click.option("--verbose", "-v", is_flag=True, help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
def check_config(config, verbose):
    """
    ì„¤ì • íŒŒì¼ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
        csv-validator check-config -c config.yml
    """
    try:
        # Data Validator ì´ˆê¸°í™”
        validator = DataValidator(config_path=config, verbose=verbose)

        # ì„¤ì • ê²€ì¦
        is_valid = validator.validate_config()

        if is_valid:
            click.echo("âœ… ì„¤ì • íŒŒì¼ì´ ìœ íš¨í•©ë‹ˆë‹¤.")

            # ì„¤ì • ìš”ì•½ ì¶œë ¥
            summary = validator.get_config_summary()
            click.echo("\nğŸ“‹ ì„¤ì • ìš”ì•½:")
            for key, value in summary.items():
                if isinstance(value, dict):
                    click.echo(f"  {key}:")
                    for sub_key, sub_value in value.items():
                        click.echo(f"    {sub_key}: {sub_value}")
                else:
                    click.echo(f"  {key}: {value}")
        else:
            click.echo("âŒ ì„¤ì • íŒŒì¼ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤.", err=True)
            sys.exit(1)

        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        validator.close()

    except Exception as e:
        click.echo(f"âŒ ì„¤ì • íŒŒì¼ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", err=True)
        if verbose:
            import traceback

            click.echo(traceback.format_exc(), err=True)
        sys.exit(1)


@cli.command()
@click.option(
    "--input",
    "-i",
    required=True,
    type=click.Path(exists=True),
    help="ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ (CSV, JSON, JSONL ì§€ì›)",
)
@click.option(
    "--output",
    "-o",
    type=click.Path(),
    help="ë¶„ì„ ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: ì…ë ¥ íŒŒì¼ê³¼ ë™ì¼í•œ ë””ë ‰í† ë¦¬)",
)
@click.option("--verbose", "-v", is_flag=True, help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
def analyze(input, output, verbose):
    """
    ë°ì´í„° íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤ (CSV, JSON, JSONL ì§€ì›).

    ì˜ˆì‹œ:
        data-validator analyze -i data.csv
        data-validator analyze -i data.json
        data-validator analyze -i data.jsonl
        data-validator analyze -i data.csv -o auto_config.yml
    """
    try:
        input_path = Path(input)
        supported_extensions = {".csv", ".json", ".jsonl"}
        if not input_path.is_file() or input_path.suffix.lower() not in supported_extensions:
            click.echo(f"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {input_path}", err=True)
            click.echo(f"ì§€ì›ë˜ëŠ” í˜•ì‹: {', '.join(supported_extensions)}", err=True)
            sys.exit(1)

        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        if output is None:
            output = input_path.parent / f"{input_path.stem}_auto_config.yml"
        else:
            output = Path(output)

        # íŒŒì¼ ë¶„ì„
        from ..utils.file_handler import FileHandler

        file_handler = FileHandler()

        # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        file_info = file_handler.get_file_info(str(input_path))
        detected_encoding = file_info.get("encoding", "utf-8")
        file_type = file_handler.detect_file_type(str(input_path))

        # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
        if file_type.value == "csv":
            detected_delimiter = file_info.get("delimiter", ",")
            # CSV íŒŒì¼ ì½ê¸°
            import pandas as pd
            df = pd.read_csv(
                str(input_path),
                encoding=detected_encoding,
                delimiter=detected_delimiter,
                nrows=1000,  # ì²˜ìŒ 1000í–‰ë§Œ ë¶„ì„
            )
            auto_config = _generate_auto_config(df, file_info, file_type)
        else:
            # JSON/JSONL íŒŒì¼ ì½ê¸°
            from ..models import FileInfo as FileInfoModel
            from ..models import FileType as FileTypeModel
            
            file_info_model = FileInfoModel(
                file_type=FileTypeModel(file_type.value),
                encoding=detected_encoding
            )
            
            data = file_handler.read_file_by_type(str(input_path), file_info_model)
            
            # JSON ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            import pandas as pd
            if data:
                # ì¤‘ì²©ëœ ê°ì²´ë¥¼ í‰ë©´í™”
                flattened_data = []
                for item in data:
                    flattened_item = file_handler.json_parser._flatten_dict(item)
                    flattened_data.append(flattened_item)
                df = pd.DataFrame(flattened_data)
            else:
                df = pd.DataFrame()
            
            auto_config = _generate_auto_config(df, file_info, file_type)

        # ì„¤ì • íŒŒì¼ ì €ì¥
        import yaml

        with open(output, "w", encoding="utf-8") as f:
            yaml.dump(
                auto_config,
                f,
                default_flow_style=False,
                allow_unicode=True,
                sort_keys=False,
            )

        click.echo(f"âœ… ìë™ ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output}")
        click.echo("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        click.echo("1. ìƒì„±ëœ ì„¤ì • íŒŒì¼ì„ ê²€í† í•˜ê³  í•„ìš”ì— ë”°ë¼ ìˆ˜ì •í•˜ì„¸ìš”")
        click.echo(
            "2. data-validator validate -c <ì„¤ì •íŒŒì¼> -i <íŒŒì¼> ëª…ë ¹ìœ¼ë¡œ ê²€ì¦ì„ ì‹¤í–‰í•˜ì„¸ìš”"
        )

        if verbose:
            click.echo(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
            click.echo(f"  - íŒŒì¼ íƒ€ì…: {file_type.value}")
            click.echo(f"  - ì¸ì½”ë”©: {detected_encoding}")
            if file_type.value == "csv":
                click.echo(f"  - êµ¬ë¶„ì: {detected_delimiter}")
            click.echo(f"  - ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
            click.echo(f"  - ë¶„ì„ëœ í–‰ ìˆ˜: {len(df)}")

    except Exception as e:
        click.echo(f"âŒ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", err=True)
        if verbose:
            import traceback

            click.echo(traceback.format_exc(), err=True)
        sys.exit(1)


def _save_single_result(result, output_dir, format, validator):
    """ë‹¨ì¼ íŒŒì¼ ê²€ì¦ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ëª… ìƒì„±
        timestamp = result.timestamp.strftime("%Y%m%d_%H%M%S")
        base_name = Path(result.file_name).stem
        output_file = output_path / f"{base_name}_{timestamp}"

        # ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥
        if format == "all":
            formats = ["markdown", "html", "json"]
        else:
            formats = [format]

        saved_files = []
        for fmt in formats:
            if fmt == "markdown":
                report = validator.formatter.generate_markdown_report(result)
                file_path = validator.formatter.save_report(
                    report, str(output_file), "markdown"
                )
            elif fmt == "html":
                report = validator.formatter.generate_html_report(result)
                file_path = validator.formatter.save_report(
                    report, str(output_file), "html"
                )
            elif fmt == "json":
                report = validator.formatter.generate_json_report(result)
                file_path = validator.formatter.save_report(
                    report, str(output_file), "json"
                )

            saved_files.append(file_path)

        # ì €ì¥ëœ íŒŒì¼ ì •ë³´ ì¶œë ¥
        click.echo(f"\nğŸ“„ ê²°ê³¼ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for file_path in saved_files:
            click.echo(f"  - {file_path}")

    except Exception as e:
        click.echo(f"âŒ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", err=True)


def _print_summary(results):
    """ê²€ì¦ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not results:
        return

    total_files = len(results)
    total_rows = sum(result.total_rows for result in results)
    total_errors = sum(len(result.errors) for result in results)
    total_time = sum(result.processing_time for result in results)

    successful_files = sum(
        1 for result in results if result.structural_valid and result.format_valid
    )
    failed_files = total_files - successful_files

    click.echo(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
    click.echo(f"  ì´ íŒŒì¼ ìˆ˜: {total_files}")
    click.echo(f"  ì„±ê³µí•œ íŒŒì¼: {successful_files}")
    click.echo(f"  ì‹¤íŒ¨í•œ íŒŒì¼: {failed_files}")
    click.echo(f"  ì´ í–‰ ìˆ˜: {total_rows:,}")
    click.echo(f"  ì´ ì˜¤ë¥˜ ìˆ˜: {total_errors}")
    click.echo(f"  ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")

    if total_time > 0:
        click.echo(f"  í‰ê·  ì²˜ë¦¬ ì†ë„: {total_rows/total_time:.0f} í–‰/ì´ˆ")


def _generate_auto_config(df, file_info, file_type):
    """íŒŒì¼ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ìë™ ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    import pandas as pd
    from datetime import datetime

    # íŒŒì¼ ì •ë³´ ì„¤ì •
    config = {
        "file_info": {
            "file_type": file_type.value,
            "expected_rows": None,  # ìë™ìœ¼ë¡œ ì„¤ì •í•˜ì§€ ì•ŠìŒ
            "encoding": file_info.get("encoding", "utf-8"),
            "delimiter": file_info.get("delimiter", ","),
            "has_header": True,
        },
        "columns": [],
    }
    
    # JSON/JSONL ì „ìš© ì„¤ì • ì¶”ê°€
    if file_type.value in ["json", "jsonl"]:
        config["file_info"]["json_schema"] = None
        config["file_info"]["json_root_path"] = None
        config["file_info"]["jsonl_array_mode"] = False

    # ê° ì»¬ëŸ¼ ë¶„ì„
    for column in df.columns:
        column_data = df[column].dropna()

        # ë°ì´í„° íƒ€ì… ì¶”ë¡ 
        data_type = _infer_data_type(column_data)

        # ì»¬ëŸ¼ ê·œì¹™ ìƒì„±
        column_rule = {
            "name": column,
            "type": data_type,
            "required": True,  # ê¸°ë³¸ì ìœ¼ë¡œ í•„ìˆ˜ë¡œ ì„¤ì •
        }

        # ë°ì´í„° íƒ€ì…ë³„ ì¶”ê°€ ê·œì¹™ ì„¤ì •
        if data_type == "integer":
            if not column_data.empty:
                try:
                    numeric_data = pd.to_numeric(column_data, errors="coerce").dropna()
                    if not numeric_data.empty:
                        column_rule["range"] = {
                            "min": int(numeric_data.min()),
                            "max": int(numeric_data.max()),
                        }
                except:
                    pass

        elif data_type == "float":
            if not column_data.empty:
                try:
                    numeric_data = pd.to_numeric(column_data, errors="coerce").dropna()
                    if not numeric_data.empty:
                        column_rule["range"] = {
                            "min": float(numeric_data.min()),
                            "max": float(numeric_data.max()),
                        }
                except:
                    pass

        elif data_type == "string":
            if not column_data.empty:
                lengths = column_data.astype(str).str.len()
                column_rule["length"] = {
                    "min": int(lengths.min()),
                    "max": int(lengths.max()),
                }

                # ë²”ì£¼í˜• ë°ì´í„°ì¸ì§€ í™•ì¸ (ê³ ìœ ê°’ì´ ì ì€ ê²½ìš°)
                unique_values = column_data.nunique()
                if unique_values <= 10 and unique_values > 1:
                    column_rule["allowed_values"] = column_data.unique().tolist()
                    column_rule["case_sensitive"] = False

        elif data_type == "datetime":
            # ì¼ë°˜ì ì¸ ë‚ ì§œ í˜•ì‹ ì‹œë„
            column_rule["format"] = "%Y-%m-%d %H:%M:%S"

        elif data_type == "email":
            # ì´ë©”ì¼ í˜•ì‹ì€ íŠ¹ë³„í•œ ì„¤ì • ë¶ˆí•„ìš”
            pass

        config["columns"].append(column_rule)

    return config


def _infer_data_type(series):
    """ì‹œë¦¬ì¦ˆ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë°ì´í„° íƒ€ì…ì„ ì¶”ë¡ í•©ë‹ˆë‹¤."""
    import pandas as pd
    import re

    # ë¹ˆ ë°ì´í„° ì²˜ë¦¬
    if series.empty:
        return "string"

    # ì´ë©”ì¼ í˜•ì‹ í™•ì¸
    email_pattern = r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
    if series.astype(str).str.match(email_pattern).any():
        return "email"

    # ë‚ ì§œ í˜•ì‹ í™•ì¸
    try:
        # ê²½ê³  ë©”ì‹œì§€ë¥¼ ì–µì œí•˜ê³  ë‚ ì§œ ë³€í™˜ ì‹œë„
        import warnings

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            pd.to_datetime(series, errors="raise")
        return "datetime"
    except:
        pass

    # ìˆ«ì í˜•ì‹ í™•ì¸
    try:
        numeric_series = pd.to_numeric(series, errors="coerce")
        if not numeric_series.isna().all():
            # ì •ìˆ˜ì¸ì§€ í™•ì¸
            if numeric_series.dropna().apply(lambda x: x.is_integer()).all():
                return "integer"
            else:
                return "float"
    except:
        pass

    # ë¶ˆë¦° í˜•ì‹ í™•ì¸
    bool_values = ["true", "false", "1", "0", "yes", "no", "y", "n"]
    if series.astype(str).str.lower().isin(bool_values).all():
        return "boolean"

    # ê¸°ë³¸ê°’ì€ ë¬¸ìì—´
    return "string"


if __name__ == "__main__":
    cli()
